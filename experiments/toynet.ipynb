{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToyNet\n",
    "\n",
    "ToyNet consists of a single linear layer along with the activation function\n",
    "$$\\mathrm{Sign}(x) = \\begin{cases}\n",
    "    +1, &\\text{if } x > 0, \\\\\n",
    "    -1, &\\text{otherwise}.\n",
    "  \\end{cases}$$\n",
    "\n",
    "This notebook is used for testing FHE inference with a simple matrix multiplication\n",
    "along with batch normalisation and ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Network\n",
    "\n",
    "The following network is trained in the clear with standard PyTorch methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import BatchNorm1d, Module, Linear, ReLU, Sequential\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from doren_bnn.xnorpp import Sign\n",
    "\n",
    "\n",
    "class ToyNet(Module):\n",
    "    def __init__(self, num_input: int = 10, num_output: int = 10, **kwargs):\n",
    "        super(ToyNet, self).__init__()\n",
    "\n",
    "        self.block = Sequential(\n",
    "            Linear(num_input, num_output, bias=False),\n",
    "            BatchNorm1d(num_output),\n",
    "            ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        num_input = self.block[0].weight.size(-1)\n",
    "\n",
    "        input = input.view(-1, 3 * 32 * 32)[:, :num_input]\n",
    "        (output_lin,) = (F.linear(Sign.apply(input), Sign.apply(self.block[0].weight)),)\n",
    "        output_bn = self.block[1](output_lin)\n",
    "        return self.block[2](output_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHE Network\n",
    "\n",
    "The following network is a FHE version of the clear network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doren_bnn_concrete import toynet\n",
    "\n",
    "\n",
    "class ToyNet_FHE(ToyNet):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ToyNet_FHE, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        assert not self.training\n",
    "\n",
    "        num_input = self.block[0].weight.size(-1)\n",
    "\n",
    "        state_dict = self.state_dict()\n",
    "        state_dict[\"block.0.weight\"] = Sign.apply(self.block[0].weight).long().tolist()\n",
    "        print(state_dict)\n",
    "\n",
    "        input = input.view(-1, 3 * 32 * 32)[:, :num_input].tolist()\n",
    "        output = []\n",
    "        for im in input:\n",
    "            output.append(toynet(state_dict, im))\n",
    "        return Tensor(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training settings\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ToyNet                                   [2, 10]                   --\n",
       "├─Sequential: 1-1                        --                        --\n",
       "│    └─Linear: 2-1                       --                        100\n",
       "│    └─BatchNorm1d: 2-2                  [2, 10]                   20\n",
       "│    └─ReLU: 2-3                         [2, 10]                   --\n",
       "==========================================================================================\n",
       "Total params: 120\n",
       "Trainable params: 120\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.03\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "NUM_INPUT = 10  # determines how many input neurons\n",
    "model = ToyNet(num_input=NUM_INPUT, num_output=10).to(device)\n",
    "\n",
    "summary(model, input_size=(BATCH_SIZE, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "criterion = CrossEntropyLoss().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-2, weight_decay=5e-6)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from doren_bnn.utils import Dataset, Experiment\n",
    "\n",
    "EXPERIMENT_ID = \"toynet\"\n",
    "experiment = Experiment(EXPERIMENT_ID, Dataset.CIFAR10, BATCH_SIZE, multiplier=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942b620764b94c5b9d9ee2295fe7c1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    NUM_EPOCHS,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.test(model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHE Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doren_bnn_concrete import preload_keys\n",
    "\n",
    "# preload_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fhe = ToyNet_FHE(num_input=NUM_INPUT, num_output=10)\n",
    "cp = experiment.load_checkpoint(model_fhe, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If FHE inference is correct, the output should be exactly the same (after rounding) as the output of clear inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('block.0.weight', [[1, 1, 1, -1, -1, -1, -1, 1, 1, 1], [1, 1, -1, 1, -1, 1, -1, 1, -1, 1], [1, 1, -1, -1, -1, 1, 1, -1, 1, 1], [-1, -1, -1, 1, -1, 1, -1, -1, -1, 1], [-1, -1, 1, -1, 1, 1, -1, 1, -1, -1], [1, -1, -1, 1, -1, 1, 1, 1, 1, -1], [-1, -1, -1, -1, -1, 1, 1, -1, 1, -1], [-1, 1, -1, 1, 1, -1, -1, 1, 1, -1], [1, -1, 1, -1, -1, 1, 1, -1, 1, 1], [1, 1, 1, 1, -1, -1, 1, 1, 1, 1]]), ('block.1.weight', tensor([0.9526, 0.9739, 0.9689, 0.9690, 0.9786, 0.8366, 0.9200, 0.8543, 0.8449,\n",
      "        0.9867])), ('block.1.bias', tensor([-0.0474, -0.0261, -0.0311,  0.0123, -0.0214, -0.1634, -0.0800, -0.1457,\n",
      "        -0.1551, -0.0315])), ('block.1.running_mean', tensor([ 0.7556,  0.1569,  0.2595, -0.3677,  0.0578,  0.1910, -0.0127,  0.0292,\n",
      "         0.2432,  0.7833])), ('block.1.running_var', tensor([ 2.9861,  2.5818,  3.9839,  9.8438,  1.9769,  6.1268, 17.2033,  1.7501,\n",
      "         3.0241, 13.2730])), ('block.1.num_batches_tracked', tensor(25))])\n",
      "Loading existing client & server keys...\n",
      "Existing client & server keys loaded.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "fc.weight not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/wei2912/Workspace/wei2912/doren-bnn/experiments/toynet.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wei2912/Workspace/wei2912/doren-bnn/experiments/toynet.ipynb#ch0000021?line=0'>1</a>\u001b[0m experiment\u001b[39m.\u001b[39;49mtest_fhe(model_fhe)\n",
      "File \u001b[0;32m~/Workspace/wei2912/doren-bnn/doren_bnn/utils.py:280\u001b[0m, in \u001b[0;36mExperiment.test_fhe\u001b[0;34m(self, model_fhe)\u001b[0m\n\u001b[1;32m    278\u001b[0m targets \u001b[39m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[39mfor\u001b[39;00m (\u001b[39minput\u001b[39m, target) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_test_loader:\n\u001b[0;32m--> 280\u001b[0m     output \u001b[39m=\u001b[39m model_fhe(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    281\u001b[0m     outputs\u001b[39m.\u001b[39mextend(output\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m    282\u001b[0m     targets\u001b[39m.\u001b[39mextend(target\u001b[39m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/Workspace/wei2912/doren-bnn/.venv/lib64/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/wei2912/Workspace/wei2912/doren-bnn/experiments/toynet.ipynb Cell 22\u001b[0m in \u001b[0;36mToyNet_FHE.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wei2912/Workspace/wei2912/doren-bnn/experiments/toynet.ipynb#ch0000021?line=17'>18</a>\u001b[0m output \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wei2912/Workspace/wei2912/doren-bnn/experiments/toynet.ipynb#ch0000021?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m im \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/wei2912/Workspace/wei2912/doren-bnn/experiments/toynet.ipynb#ch0000021?line=19'>20</a>\u001b[0m     output\u001b[39m.\u001b[39mappend(toynet(state_dict, im))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wei2912/Workspace/wei2912/doren-bnn/experiments/toynet.ipynb#ch0000021?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Tensor(output)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: fc.weight not found"
     ]
    }
   ],
   "source": [
    "experiment.test_fhe(model_fhe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fbf9bce7bb1e4fc9ecfb96977920c6a9559d86ace38026585ed867662b29060"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
