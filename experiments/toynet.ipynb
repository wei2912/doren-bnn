{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToyNet\n",
    "\n",
    "ToyNet consists of a single linear layer along with the activation function\n",
    "$$\\mathrm{Sign}(x) = \\begin{cases}\n",
    "    +1, &\\text{if } x > 0, \\\\\n",
    "    -1, &\\text{otherwise}.\n",
    "  \\end{cases}$$\n",
    "\n",
    "This notebook is used for testing FHE inference with a simple matrix multiplication\n",
    "along with bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Network\n",
    "\n",
    "The following network is trained in the clear with standard PyTorch methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import Module, Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from doren_bnn.xnorpp import Sign\n",
    "\n",
    "\n",
    "class ToyNet(Module):\n",
    "    def __init__(self, num_input: int = 1024, num_classes: int = 1000, **kwargs):\n",
    "        super(ToyNet, self).__init__()\n",
    "\n",
    "        self.fc = Linear(num_input, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        num_input = self.fc.weight.size(-1)\n",
    "\n",
    "        input = input.view(-1, 3 * 224 * 224)[:, :num_input]\n",
    "        return Sign.apply(F.linear(Sign.apply(input), Sign.apply(self.fc.weight)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHE Network\n",
    "\n",
    "The following network is a FHE version of the clear network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doren_bnn_concrete import toynet\n",
    "\n",
    "\n",
    "class ToyNet_FHE(ToyNet):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ToyNet_FHE, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        assert not self.training\n",
    "\n",
    "        num_input = self.fc.weight.size(-1)\n",
    "\n",
    "        state_dict = self.state_dict()\n",
    "        state_dict[\"fc.weight\"] = [\n",
    "            [w > 0 for w in row] for row in self.fc.weight.tolist()\n",
    "        ]\n",
    "\n",
    "        input = input.view(-1, 3 * 224 * 224)[:, :num_input].tolist()\n",
    "        output = []\n",
    "        for im in input:\n",
    "            output.append(toynet(state_dict, im))\n",
    "        return Tensor(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training settings\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ToyNet                                   [2, 10]                   --\n",
       "├─Linear: 1-1                            --                        100\n",
       "==========================================================================================\n",
       "Total params: 100\n",
       "Trainable params: 100\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 1.20\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "NUM_INPUT = 10  # determines how many input neurons\n",
    "model = ToyNet(num_input=NUM_INPUT, num_classes=10).to(device)\n",
    "\n",
    "summary(model, input_size=(BATCH_SIZE, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "criterion = CrossEntropyLoss().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-2, weight_decay=5e-6)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from doren_bnn.utils import Dataset, Experiment\n",
    "\n",
    "EXPERIMENT_ID = \"toynet\"\n",
    "experiment = Experiment(EXPERIMENT_ID, Dataset.CIFAR10, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b182e996924434bbdab84e97520e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.train(\n",
    "    device,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    NUM_EPOCHS,\n",
    "    resume=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "experiment.test(device, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHE Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing secret keys...\n",
      "Existing secret keys loaded.\n"
     ]
    }
   ],
   "source": [
    "from doren_bnn_concrete import preload_keys\n",
    "\n",
    "preload_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fhe = ToyNet_FHE(num_input=NUM_INPUT, num_classes=10)\n",
    "cp = experiment.load_checkpoint(model_fhe, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If FHE inference is correct, the output should be exactly the same (after rounding) as the output of clear inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.999999999999892, 3.999999999998245, 4.000000000000346, -5.999999999997441, 8.000000000001258, 1.9999999999986997, 3.9999999999961897, 7.9999999999987494, 7.999999999999435, 4.0000000000005205]\n",
      "Encoder { o: -10.0, delta: 64.0, nb_bit_precision: 1, nb_bit_padding: 5, round: false }\n",
      "Encoder { o: -1.0, delta: 4.0, nb_bit_precision: 1, nb_bit_padding: 9, round: false }\n",
      "[5.999999999998707, 3.9999999999996163, 3.9999999999983515, -5.999999999999916, 8.000000000000789, 1.999999999999261, 3.9999999999991935, 7.999999999998703, 7.999999999999915, 4.000000000003164]\n",
      "Encoder { o: -10.0, delta: 64.0, nb_bit_precision: 1, nb_bit_padding: 5, round: false }\n",
      "Encoder { o: -1.0, delta: 4.0, nb_bit_precision: 1, nb_bit_padding: 9, round: false }\n",
      "tensor([[-0.9979,  0.9779, -0.9427, -0.9685,  0.9843, -0.9731,  1.0000,  0.9989,\n",
      "          0.9714, -0.9967],\n",
      "        [ 1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -0.9689,  1.0000,\n",
      "          1.0000,  0.9619]])\n"
     ]
    }
   ],
   "source": [
    "experiment.test_fhe(model_fhe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('doren-bnn-Z3Z8sIfT-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e83aaab8b010134e55ad60062ddf3e0da69d95d3f62b8b83a253f488e46fa313"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
