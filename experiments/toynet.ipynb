{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToyNet\n",
    "\n",
    "ToyNet consists of a single linear layer along with the activation function\n",
    "$$\\mathrm{Sign}(x) = \\begin{cases}\n",
    "    +1, &\\text{if } x > 0, \\\\\n",
    "    -1, &\\text{otherwise}.\n",
    "  \\end{cases}$$\n",
    "\n",
    "This notebook is used for testing FHE inference with a simple matrix multiplication\n",
    "along with batch normalisation and ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Network\n",
    "\n",
    "The following network is trained in the clear with standard PyTorch methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import BatchNorm1d, Module, Linear, ReLU, Sequential\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from doren_bnn.xnorpp import Sign\n",
    "\n",
    "\n",
    "class ToyNet(Module):\n",
    "    def __init__(self, num_input: int = 10, num_output: int = 10, **kwargs):\n",
    "        super(ToyNet, self).__init__()\n",
    "\n",
    "        self.block = Sequential(\n",
    "            Linear(num_input, num_output, bias=False),\n",
    "            BatchNorm1d(num_output),\n",
    "            ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        num_input = self.block[0].weight.size(-1)\n",
    "\n",
    "        input = input.view(-1, 3 * 32 * 32)[:, :num_input]\n",
    "        (output_lin,) = (F.linear(Sign.apply(input), Sign.apply(self.block[0].weight)),)\n",
    "        output_bn = self.block[1](output_lin)\n",
    "        output = self.block[2](output_bn)\n",
    "        if not self.training:\n",
    "            print(output[:, :10])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHE Network\n",
    "\n",
    "The following network is a FHE version of the clear network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doren_bnn_concrete import toynet\n",
    "\n",
    "\n",
    "class ToyNet_FHE(ToyNet):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ToyNet_FHE, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        assert not self.training\n",
    "\n",
    "        num_input = self.block[0].weight.size(-1)\n",
    "\n",
    "        state_dict = self.state_dict()\n",
    "        state_dict[\"block.0.weight\"] = Sign.apply(self.block[0].weight).long().tolist()\n",
    "        print(state_dict)\n",
    "\n",
    "        input = input.view(-1, 3 * 32 * 32)[:, :num_input].tolist()\n",
    "        output = []\n",
    "        for im in input:\n",
    "            output_tn = toynet(state_dict)\n",
    "            output.append(output_tn)\n",
    "            print(output_tn[:10])\n",
    "        return Tensor(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training settings\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "NUM_INPUT = 10  # determines how many input neurons\n",
    "model = ToyNet(num_input=NUM_INPUT, num_output=10).to(device)\n",
    "\n",
    "summary(model, input_size=(BATCH_SIZE, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "criterion = CrossEntropyLoss().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-2, weight_decay=5e-6)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doren_bnn.utils import Dataset, Experiment\n",
    "\n",
    "EXPERIMENT_ID = \"toynet\"\n",
    "experiment = Experiment(EXPERIMENT_ID, Dataset.CIFAR10, BATCH_SIZE, multiplier=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    NUM_EPOCHS,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.test(model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHE Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doren_bnn_concrete import preload_keys\n",
    "\n",
    "preload_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fhe = ToyNet_FHE(num_input=NUM_INPUT, num_output=10)\n",
    "cp = experiment.load_checkpoint(model_fhe, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If FHE inference is correct, the output should be exactly the same (after rounding) as the output of clear inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.test_fhe(model_fhe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fbf9bce7bb1e4fc9ecfb96977920c6a9559d86ace38026585ed867662b29060"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
